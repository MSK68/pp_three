# Ход выполнения на 13.12.2024

# Работа с данными

На текущем этапе выполнения задачи используются предоставленные датасеты с обучающей выборкой (train.csv), валидационной выборкой (valid.csv), тестовой выборкой с неразмеченными данными (test_without_answers.csv).

В бейзлайне предобработка данных включает в себя избавление текста от капитализаци, знаков пунктуации, удаление небуквенных символов и пробелов. Наша команда включила также нормализацию, анализ пропусков и дубликатов с последующим удалением.

В токенизацию добавлено автоматическое определние длины текста.

# Изменения модели

В качестве изменений выполнено:
- динамическое определение размера скрытых слоёв вместо жёсткого указания hidden_dim=768;
- Dropout-слой для регуляризации.

В оптимизаторе используем AdamW вместо Adam и добавляем регуляризацию L2.

При обучении внедрили Scheduler для постепенного уменьшения Learning rate, для чего также рассчитываем ошибку.

# Оценка модели

На валидационных данных при обучении в течение трех эпох получили значение Valid loss: 0.23307764687958885, на неразмеченных данных - Valid loss: 0.2817318362557378.

# Выводы

Модель имеет склонность к переобучению при количестве эпох больше трех.

# Дальнейшие планы

- дополнить датасет с обучающей выборкой;
- продолжить оптимизацию гиперпараметров;
- оптимизировать процесс обучение модели;
- добавить визуалиацию метрик и процесса обучения.
