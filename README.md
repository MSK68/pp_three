# Классификация эмоций на основе текста

Этот проект реализует многометочную классификацию эмоций с использованием модели BERT. В процессе работы данные очищаются, анализируются, обучается нейронная сеть, а также выполняется предсказание эмоций.

---

## Содержание

1. [Требования](#требования)
2. [Датасеты](#датасеты)
3. [Установка](#установка)
4. [Предобработка](#предобработка)
5. [Обучение и валидация](#обучение-и-валидация)
6. [Тестирование](#тестирование)
7. [Создание файла сабмита](#создание-файла-сабмита)
8. [Результаты](#результаты)

---

## Требования

Для запуска проекта установите следующие библиотеки:

```bash
pip install -q transformers datasets librosa torch scikit-learn matplotlib pandas
```

---

## Датасеты

Скачайте данные по [ссылке](https://disk.yandex.ru/d/awG8jCY01BGcAQ) и разместите файлы следующим образом:

```
.
├── train.csv
├── valid.csv
├── content
│   └── test_without_answers.csv
```

### Метки

Датасет содержит следующие метки эмоций:

- `anger`
- `disgust`
- `fear`
- `joy`
- `sadness`
- `surprise`
- `neutral`

---

## Установка

1. Клонируйте репозиторий и перейдите в папку проекта.
2. Установите все необходимые библиотеки, указанные в разделе "Требования".

---

## Предобработка

1. **Анализ данных**:
   - Проверка на пропущенные значения и дубликаты.
   - Анализ уникальных символов в текстах.
   - Построение гистограмм распределения эмоций и их со-встречаемости.
2. **Очистка данных**: 
   - Перевод текста в нижний регистр
   - Удаление лишних символов
   - Нормализация пробелов
   - Удаление дубликатов

Пример команды для проверки данных на пропуски:

---

## Обучение и валидация

1. Определяется модель на основе `AutoModel` из библиотеки Transformers.
2. Токенизация датасета и подготовка DataLoader для PyTorch.
3. Обучение модели с использованием функции ошибки `BCEWithLogitsLoss` и оптимизатора Adam.

Пример запуска обучения:

```python
for epoch in range(epochs):
    print(f"Epoch: {epoch}")
    model = train(model, criterion, optimizer, train_dataloader)
    val_outputs, val_targets = validation(model, criterion, valid_dataloader)
```

---

## Тестирование

1. Загрузка и предобработка тестового датасета.
2. Генерация предсказаний с использованием обученной модели.

Пример команды для тестирования:

```python
outputs, _ = validation(model, criterion, test_dataloader)
```

---

## Создание файла сабмита

1. Обновите файл `test_without_answers.csv` предсказанными значениями.
2. Сохраните результат в файл `submission.csv`.

Пример команды:

```python
df[labels] = outputs.astype(int)
df.to_csv("/content/submission.csv", index=False)
```

---

## Результаты

На валидационных данных при обучении в течение трех эпох получили значение:
- Valid loss: 0.23307764687958885
На неразмеченных данных:
- Valid loss: 0.2817318362557378

---



